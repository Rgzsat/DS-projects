{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQFQD2LHY9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8290c564-7635-4f89-cbf8-676ff5309e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token generation in cmd"
      ],
      "metadata": {
        "id": "la5WXUgAZf47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "API_TOKEN = '24bb102a-87a2-4b95-8eff-24e29eb94217'\n",
        "BASE_URL = 'https://web-api.tp.entsoe.eu/api'\n",
        "control_area_domain = '10Y1001A1001A83F'\n",
        "DOCUMENT_TYPE = 'A85'\n",
        "\n",
        "def fetch_data_for_period(start_str, end_str, max_retries=5):\n",
        "    params = {\n",
        "        'documentType': DOCUMENT_TYPE,\n",
        "        'controlArea_Domain': control_area_domain,\n",
        "        'periodStart': start_str,\n",
        "        'periodEnd': end_str,\n",
        "        'securityToken': API_TOKEN,\n",
        "    }\n",
        "    retry_delay = 5\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt+1}: fetching {start_str} to {end_str}\")\n",
        "            resp = requests.get(BASE_URL, params=params, timeout=30)\n",
        "            resp.raise_for_status()\n",
        "            content = resp.content\n",
        "            # detect zip\n",
        "            if 'application/zip' in resp.headers.get('Content-Type', '') or content.startswith(b'PK'):\n",
        "                z = zipfile.ZipFile(BytesIO(content))\n",
        "                xml_filename = z.namelist()[0]\n",
        "                xml_content = z.read(xml_filename)\n",
        "                return xml_content\n",
        "            else:\n",
        "                return content\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(\"Timeout, retrying...\")\n",
        "            time.sleep(retry_delay)\n",
        "            retry_delay *= 2\n",
        "        except Exception as e:\n",
        "            print(\"Error in fetch:\", e)\n",
        "            break\n",
        "    return None\n",
        "\n",
        "def parse_balancing_A85(xml_content):\n",
        "    root = ET.fromstring(xml_content)\n",
        "\n",
        "    # detect namespace\n",
        "    nsuri = ''\n",
        "    if root.tag.startswith('{'):\n",
        "        nsuri = root.tag.split('}')[0].strip('{')\n",
        "    ns = {'ns': nsuri} if nsuri else {}\n",
        "\n",
        "    print(\"Root:\", root.tag, \"Namespace:\", nsuri)\n",
        "\n",
        "    records = []\n",
        "    # find TimeSeries elements\n",
        "    ts_path = './/ns:TimeSeries' if nsuri else './/TimeSeries'\n",
        "    for ts in root.findall(ts_path, ns):\n",
        "        # inside each TimeSeries, find Period\n",
        "        period_path = 'ns:Period' if nsuri else 'Period'\n",
        "        for period in ts.findall(period_path, ns):\n",
        "            # timeInterval start/end\n",
        "            ti = period.find('ns:timeInterval', ns) if nsuri else period.find('timeInterval')\n",
        "            start = ti.find('ns:start', ns).text if ti is not None and ti.find('ns:start', ns) is not None else None\n",
        "            end = ti.find('ns:end', ns).text if ti is not None and ti.find('ns:end', ns) is not None else None\n",
        "\n",
        "            # iterate through Point elements\n",
        "            point_path = 'ns:Point' if nsuri else 'Point'\n",
        "            for point in period.findall(point_path, ns):\n",
        "                pos_el = point.find('ns:position', ns) if nsuri else point.find('position')\n",
        "                # here use imbalance_Price.amount\n",
        "                val_el = point.find('ns:imbalance_Price.amount', ns) if nsuri else point.find('imbalance_Price.amount')\n",
        "                cat_el = point.find('ns:imbalance_Price.category', ns) if nsuri else point.find('imbalance_Price.category')\n",
        "\n",
        "                if pos_el is None or val_el is None:\n",
        "                    continue\n",
        "\n",
        "                rec = {\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'position': int(pos_el.text),\n",
        "                    'imbalance_price': float(val_el.text),\n",
        "                }\n",
        "                if cat_el is not None:\n",
        "                    rec['price_category'] = cat_el.text\n",
        "                records.append(rec)\n",
        "\n",
        "    print(\"Parsed records:\", len(records))\n",
        "    return records\n",
        "\n",
        "def daterange(start, end):\n",
        "    for n in range(int((end - start).days)):\n",
        "        yield start + timedelta(n)\n",
        "\n",
        "def yyyymmddHHMM(dt):\n",
        "    return dt.strftime('%Y%m%d%H%M')\n",
        "\n",
        "# Main\n",
        "start_date = datetime(2025, 9, 15, 0, 0)\n",
        "end_date = datetime(2025, 9, 30, 23, 59)\n",
        "\n",
        "all_recs = []\n",
        "for d in daterange(start_date, end_date + timedelta(days=1)):\n",
        "    day0 = d.replace(hour=0, minute=0)\n",
        "    day1 = day0 + timedelta(days=1)\n",
        "    s = yyyymmddHHMM(day0)\n",
        "    e = yyyymmddHHMM(day1)\n",
        "    xml = fetch_data_for_period(s, e)\n",
        "    if xml:\n",
        "        print(f\"Fetched {s}-{e}, size {len(xml)}\")\n",
        "        recs = parse_balancing_A85(xml)\n",
        "        all_recs.extend(recs)\n",
        "    else:\n",
        "        print(\"No xml\")\n",
        "\n",
        "df = pd.DataFrame(all_recs)\n",
        "print(\"Total rows in df:\", len(df))\n",
        "print(df.head())\n",
        "\n",
        "df.to_excel('entsoe_imbalance_prices.xlsx', index=False)\n",
        "print(\"Saved to entsoe_imbalance_prices.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1teRvlPhbCq",
        "outputId": "28b9a490-4497-46b3-ec53-ccef75104e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: fetching 202509150000 to 202509160000\n",
            "Fetched 202509150000-202509160000, size 35359\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509160000 to 202509170000\n",
            "Fetched 202509160000-202509170000, size 35365\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509170000 to 202509180000\n",
            "Fetched 202509170000-202509180000, size 35349\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509180000 to 202509190000\n",
            "Fetched 202509180000-202509190000, size 35395\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509190000 to 202509200000\n",
            "Fetched 202509190000-202509200000, size 35381\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509200000 to 202509210000\n",
            "Fetched 202509200000-202509210000, size 35337\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509210000 to 202509220000\n",
            "Fetched 202509210000-202509220000, size 35373\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509220000 to 202509230000\n",
            "Fetched 202509220000-202509230000, size 35339\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509230000 to 202509240000\n",
            "Fetched 202509230000-202509240000, size 35371\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509240000 to 202509250000\n",
            "Fetched 202509240000-202509250000, size 35369\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509250000 to 202509260000\n",
            "Fetched 202509250000-202509260000, size 35409\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509260000 to 202509270000\n",
            "Fetched 202509260000-202509270000, size 35407\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509270000 to 202509280000\n",
            "Fetched 202509270000-202509280000, size 35419\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509280000 to 202509290000\n",
            "Fetched 202509280000-202509290000, size 35389\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509290000 to 202509300000\n",
            "Fetched 202509290000-202509300000, size 35387\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Attempt 1: fetching 202509300000 to 202510010000\n",
            "Fetched 202509300000-202510010000, size 35387\n",
            "Root: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records: 192\n",
            "Total rows in df: 3072\n",
            "               start                end  position  imbalance_price  \\\n",
            "0  2025-09-15T00:00Z  2025-09-15T22:00Z         1           124.46   \n",
            "1  2025-09-15T00:00Z  2025-09-15T22:00Z         2            69.22   \n",
            "2  2025-09-15T00:00Z  2025-09-15T22:00Z         3            68.99   \n",
            "3  2025-09-15T00:00Z  2025-09-15T22:00Z         4            52.71   \n",
            "4  2025-09-15T00:00Z  2025-09-15T22:00Z         5           -89.69   \n",
            "\n",
            "  price_category  \n",
            "0            A04  \n",
            "1            A04  \n",
            "2            A04  \n",
            "3            A04  \n",
            "4            A04  \n",
            "Saved to entsoe_imbalance_prices.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil import parser\n",
        "import time\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "API_TOKEN = 'INTRODUCE YOUR TOKEN HERE'\n",
        "BASE_URL = 'https://web-api.tp.entsoe.eu/api'\n",
        "control_area_domain = '10Y1001A1001A83F'\n",
        "DOCUMENT_TYPE = 'A85'  # Imbalance Prices (Balancing)\n",
        "\n",
        "def fetch_data_for_period(start_str, end_str, max_retries=5):\n",
        "    params = {\n",
        "        'documentType': DOCUMENT_TYPE,\n",
        "        'controlArea_Domain': control_area_domain,\n",
        "        'periodStart': start_str,\n",
        "        'periodEnd': end_str,\n",
        "        'securityToken': API_TOKEN,\n",
        "    }\n",
        "    retry_delay = 5\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt+1}: fetching {start_str} to {end_str}\")\n",
        "            resp = requests.get(BASE_URL, params=params, timeout=30)\n",
        "            resp.raise_for_status()\n",
        "            content = resp.content\n",
        "            # If it's a ZIP archive, unzip\n",
        "            if 'application/zip' in resp.headers.get('Content-Type', '') or content.startswith(b'PK'):\n",
        "                zf = zipfile.ZipFile(BytesIO(content))\n",
        "                xml_filename = zf.namelist()[0]\n",
        "                xml_content = zf.read(xml_filename)\n",
        "                return xml_content\n",
        "            else:\n",
        "                return content\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"Timeout on attempt {attempt+1}, retrying after {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "            retry_delay *= 2\n",
        "        except Exception as e:\n",
        "            print(\"Error fetching data:\", e)\n",
        "            break\n",
        "    print(\"Failed to fetch after retries.\")\n",
        "    return None\n",
        "\n",
        "def parse_balancing_A85(xml_content):\n",
        "    root = ET.fromstring(xml_content)\n",
        "    # Determine namespace\n",
        "    nsuri = ''\n",
        "    if root.tag.startswith('{'):\n",
        "        nsuri = root.tag.split('}')[0].strip('{')\n",
        "    ns = {'ns': nsuri} if nsuri else {}\n",
        "\n",
        "    print(\"Root tag:\", root.tag, \"Namespace:\", nsuri)\n",
        "\n",
        "    records = []\n",
        "    # Use TimeSeries elements\n",
        "    ts_path = './/ns:TimeSeries' if nsuri else './/TimeSeries'\n",
        "    for ts in root.findall(ts_path, ns):\n",
        "        # Inside each TimeSeries, find Period\n",
        "        period_path = 'ns:Period' if nsuri else 'Period'\n",
        "        for period in ts.findall(period_path, ns):\n",
        "            # Extract timeInterval start / end\n",
        "            ti = period.find('ns:timeInterval', ns) if nsuri else period.find('timeInterval')\n",
        "            start = None\n",
        "            end = None\n",
        "            if ti is not None:\n",
        "                st = ti.find('ns:start', ns) if nsuri else ti.find('start')\n",
        "                en = ti.find('ns:end', ns) if nsuri else ti.find('end')\n",
        "                if st is not None:\n",
        "                    start = st.text\n",
        "                if en is not None:\n",
        "                    end = en.text\n",
        "\n",
        "            # Now iterate through Point elements\n",
        "            point_path = 'ns:Point' if nsuri else 'Point'\n",
        "            for point in period.findall(point_path, ns):\n",
        "                pos_el = point.find('ns:position', ns) if nsuri else point.find('position')\n",
        "                val_el = point.find('ns:imbalance_Price.amount', ns) if nsuri else point.find('imbalance_Price.amount')\n",
        "                cat_el = point.find('ns:imbalance_Price.category', ns) if nsuri else point.find('imbalance_Price.category')\n",
        "\n",
        "                if pos_el is None or val_el is None:\n",
        "                    continue\n",
        "\n",
        "                rec = {\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'position': int(pos_el.text),\n",
        "                    'imbalance_price': float(val_el.text),\n",
        "                }\n",
        "                if cat_el is not None and cat_el.text is not None:\n",
        "                    rec['price_category'] = cat_el.text\n",
        "                records.append(rec)\n",
        "\n",
        "    print(\"Parsed records count:\", len(records))\n",
        "    return records\n",
        "\n",
        "def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "def yyyymmddHHMM(dt):\n",
        "    return dt.strftime('%Y%m%d%H%M')\n",
        "\n",
        "def compute_timestamp(start_str, position):\n",
        "    \"\"\"\n",
        "    Given ISO start_str (e.g. '2025-09-15T00:00Z') and a 1‑based position,\n",
        "    return a datetime offset by (position ‑ 1) * 15 minutes.\n",
        "    Adjust the interval (15 min) if your data uses a different granularity.\n",
        "    \"\"\"\n",
        "    dt0 = parser.isoparse(start_str)\n",
        "    # Typically intervals are 15 minutes each; adjust multiplier if needed\n",
        "    offset = timedelta(minutes=15 * (position - 1))\n",
        "    return dt0 + offset\n",
        "\n",
        "def main():\n",
        "    # Define your date range\n",
        "    start_date = datetime(2025, 9, 15, 0, 0)\n",
        "    end_date = datetime(2025, 9, 30, 23, 59)\n",
        "\n",
        "    all_recs = []\n",
        "    for d in daterange(start_date, end_date + timedelta(days=1)):\n",
        "        day0 = d.replace(hour=0, minute=0)\n",
        "        day1 = day0 + timedelta(days=1)\n",
        "        s = yyyymmddHHMM(day0)\n",
        "        e = yyyymmddHHMM(day1)\n",
        "        xml = fetch_data_for_period(s, e)\n",
        "        if xml:\n",
        "            print(f\"Fetched data {s} to {e}, size {len(xml)}\")\n",
        "            recs = parse_balancing_A85(xml)\n",
        "            all_recs.extend(recs)\n",
        "        else:\n",
        "            print(f\"No data for interval {s}-{e}\")\n",
        "\n",
        "    df = pd.DataFrame(all_recs)\n",
        "    print(\"Total rows in df:\", len(df))\n",
        "    print(df.head())\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"WARNING: DataFrame is empty — no parsed records.\")\n",
        "    else:\n",
        "        # Compute and format timestamp\n",
        "        df['timestamp'] = df.apply(lambda row: compute_timestamp(row['start'], row['position']), axis=1)\n",
        "        df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Optionally, keep only desired columns\n",
        "        df = df[['timestamp', 'imbalance_price', 'price_category']]\n",
        "\n",
        "        # Save to Excel\n",
        "        output_fname = 'entsoe_imbalance_prices.xlsx'\n",
        "        df.to_excel(output_fname, index=False)\n",
        "        print(f\"Saved to {output_fname}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN_TN667mrqf",
        "outputId": "a24d01ed-c0a2-4f3c-9c70-0269d5903216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: fetching 202509150000 to 202509160000\n",
            "Fetched data 202509150000 to 202509160000, size 35359\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509160000 to 202509170000\n",
            "Fetched data 202509160000 to 202509170000, size 35365\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509170000 to 202509180000\n",
            "Fetched data 202509170000 to 202509180000, size 35349\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509180000 to 202509190000\n",
            "Fetched data 202509180000 to 202509190000, size 35395\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509190000 to 202509200000\n",
            "Fetched data 202509190000 to 202509200000, size 35381\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509200000 to 202509210000\n",
            "Fetched data 202509200000 to 202509210000, size 35337\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509210000 to 202509220000\n",
            "Fetched data 202509210000 to 202509220000, size 35373\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509220000 to 202509230000\n",
            "Fetched data 202509220000 to 202509230000, size 35339\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509230000 to 202509240000\n",
            "Fetched data 202509230000 to 202509240000, size 35371\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509240000 to 202509250000\n",
            "Fetched data 202509240000 to 202509250000, size 35369\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509250000 to 202509260000\n",
            "Fetched data 202509250000 to 202509260000, size 35409\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509260000 to 202509270000\n",
            "Fetched data 202509260000 to 202509270000, size 35407\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509270000 to 202509280000\n",
            "Fetched data 202509270000 to 202509280000, size 35419\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509280000 to 202509290000\n",
            "Fetched data 202509280000 to 202509290000, size 35389\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509290000 to 202509300000\n",
            "Fetched data 202509290000 to 202509300000, size 35387\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509300000 to 202510010000\n",
            "Fetched data 202509300000 to 202510010000, size 35387\n",
            "Root tag: {urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4}Balancing_MarketDocument Namespace: urn:iec62325.351:tc57wg16:451-6:balancingdocument:4:4\n",
            "Parsed records count: 192\n",
            "Total rows in df: 3072\n",
            "               start                end  position  imbalance_price  \\\n",
            "0  2025-09-15T00:00Z  2025-09-15T22:00Z         1           124.46   \n",
            "1  2025-09-15T00:00Z  2025-09-15T22:00Z         2            69.22   \n",
            "2  2025-09-15T00:00Z  2025-09-15T22:00Z         3            68.99   \n",
            "3  2025-09-15T00:00Z  2025-09-15T22:00Z         4            52.71   \n",
            "4  2025-09-15T00:00Z  2025-09-15T22:00Z         5           -89.69   \n",
            "\n",
            "  price_category  \n",
            "0            A04  \n",
            "1            A04  \n",
            "2            A04  \n",
            "3            A04  \n",
            "4            A04  \n",
            "Saved to entsoe_imbalance_prices.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil import parser\n",
        "import time\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "API_TOKEN = 'INTRODUCE YOUR TOKEN HERE'\n",
        "BASE_URL = 'https://web-api.tp.entsoe.eu/api'\n",
        "control_area_domain = '10Y1001A1001A83F'  # Germany/Luxembourg\n",
        "DOCUMENT_TYPE = 'A85'  # Imbalance Prices\n",
        "\n",
        "def fetch_data_for_period(start_str, end_str, max_retries=5):\n",
        "    params = {\n",
        "        'documentType': DOCUMENT_TYPE,\n",
        "        'controlArea_Domain': control_area_domain,\n",
        "        'periodStart': start_str,\n",
        "        'periodEnd': end_str,\n",
        "        'securityToken': API_TOKEN,\n",
        "    }\n",
        "    retry_delay = 5\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Attempt {attempt+1}: fetching {start_str} to {end_str}\")\n",
        "            resp = requests.get(BASE_URL, params=params, timeout=30)\n",
        "            resp.raise_for_status()\n",
        "            content = resp.content\n",
        "            if 'application/zip' in resp.headers.get('Content-Type', '') or content.startswith(b'PK'):\n",
        "                zf = zipfile.ZipFile(BytesIO(content))\n",
        "                xml_filename = zf.namelist()[0]\n",
        "                xml_content = zf.read(xml_filename)\n",
        "                return xml_content\n",
        "            else:\n",
        "                return content\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"Timeout on attempt {attempt+1}, retrying after {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "            retry_delay *= 2\n",
        "        except Exception as e:\n",
        "            print(\"Error fetching data:\", e)\n",
        "            break\n",
        "    print(\"Failed to fetch after retries.\")\n",
        "    return None\n",
        "\n",
        "def parse_balancing_A85(xml_content):\n",
        "    root = ET.fromstring(xml_content)\n",
        "    nsuri = ''\n",
        "    if root.tag.startswith('{'):\n",
        "        nsuri = root.tag.split('}')[0].strip('{')\n",
        "    ns = {'ns': nsuri} if nsuri else {}\n",
        "\n",
        "    records = []\n",
        "    ts_path = './/ns:TimeSeries' if nsuri else './/TimeSeries'\n",
        "    for ts in root.findall(ts_path, ns):\n",
        "        period_path = 'ns:Period' if nsuri else 'Period'\n",
        "        for period in ts.findall(period_path, ns):\n",
        "            ti = period.find('ns:timeInterval', ns) if nsuri else period.find('timeInterval')\n",
        "            start = None\n",
        "            if ti is not None:\n",
        "                st = ti.find('ns:start', ns) if nsuri else ti.find('start')\n",
        "                if st is not None:\n",
        "                    start = st.text\n",
        "\n",
        "            point_path = 'ns:Point' if nsuri else 'Point'\n",
        "            for point in period.findall(point_path, ns):\n",
        "                pos_el = point.find('ns:position', ns) if nsuri else point.find('position')\n",
        "                val_el = point.find('ns:imbalance_Price.amount', ns) if nsuri else point.find('imbalance_Price.amount')\n",
        "                cat_el = point.find('ns:imbalance_Price.category', ns) if nsuri else point.find('imbalance_Price.category')\n",
        "\n",
        "                if pos_el is None or val_el is None or cat_el is None:\n",
        "                    continue\n",
        "\n",
        "                rec = {\n",
        "                    'start': start,\n",
        "                    'position': int(pos_el.text),\n",
        "                    'price': float(val_el.text),\n",
        "                    'category': cat_el.text.strip()\n",
        "                }\n",
        "                records.append(rec)\n",
        "    print(\"Parsed records count:\", len(records))\n",
        "    return records\n",
        "\n",
        "def compute_timestamp(start_str, position):\n",
        "    dt0 = parser.isoparse(start_str)\n",
        "    return dt0 + timedelta(minutes=15 * (position - 1))\n",
        "\n",
        "def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "def yyyymmddHHMM(dt):\n",
        "    return dt.strftime('%Y%m%d%H%M')\n",
        "\n",
        "def main():\n",
        "    start_date = datetime(2025, 9, 15, 0, 0)\n",
        "    end_date = datetime(2025, 10, 1, 0, 0)\n",
        "\n",
        "    all_recs = []\n",
        "    for d in daterange(start_date, end_date):\n",
        "        day0 = d.replace(hour=0, minute=0)\n",
        "        day1 = day0 + timedelta(days=1)\n",
        "        s = yyyymmddHHMM(day0)\n",
        "        e = yyyymmddHHMM(day1)\n",
        "        xml = fetch_data_for_period(s, e)\n",
        "        if xml:\n",
        "            print(f\"Fetched data {s} to {e}, size {len(xml)}\")\n",
        "            recs = parse_balancing_A85(xml)\n",
        "            all_recs.extend(recs)\n",
        "\n",
        "    if not all_recs:\n",
        "        print(\"No records found.\")\n",
        "        return\n",
        "\n",
        "    raw_df = pd.DataFrame(all_recs)\n",
        "    print(\"Total rows in raw df:\", len(raw_df))\n",
        "\n",
        "    raw_df['timestamp'] = raw_df.apply(lambda row: compute_timestamp(row['start'], row['position']), axis=1)\n",
        "    raw_df = raw_df[['timestamp', 'price', 'category']]\n",
        "\n",
        "    # ✅ Show actual categories found\n",
        "    print(\"Categories found in data:\", raw_df['category'].unique())\n",
        "\n",
        "    # ✅ Pivot by category\n",
        "    pivot_df = raw_df.pivot_table(\n",
        "        index='timestamp',\n",
        "        columns='category',\n",
        "        values='price',\n",
        "        aggfunc='first'\n",
        "    ).reset_index()\n",
        "\n",
        "    # ✅ Rename based on actual found codes\n",
        "    col_map = {\n",
        "        'A04': 'imbalance_price',\n",
        "        'A05': 'downward_price',\n",
        "        'A06': 'upward_price'\n",
        "    }\n",
        "    pivot_df.rename(columns=col_map, inplace=True)\n",
        "\n",
        "    # ✅ Ensure all 3 columns exist\n",
        "    for col in ['imbalance_price', 'upward_price', 'downward_price']:\n",
        "        if col not in pivot_df:\n",
        "            pivot_df[col] = None\n",
        "\n",
        "    pivot_df.sort_values(by='timestamp', inplace=True)\n",
        "    pivot_df['timestamp'] = pivot_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # ✅ Show preview\n",
        "    print(\"\\nFinal DataFrame preview:\")\n",
        "    print(pivot_df.head(20))\n",
        "\n",
        "    # ✅ Save to Excel\n",
        "    pivot_df.to_excel('entsoe_prices_combined.xlsx', index=False)\n",
        "    print(\"✅ Saved to entsoe_prices_combined.xlsx\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHiZZAX-lWht",
        "outputId": "2e01dfef-ba1b-40d6-b92c-10a63bcaf8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1: fetching 202509150000 to 202509160000\n",
            "Fetched data 202509150000 to 202509160000, size 35359\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509160000 to 202509170000\n",
            "Fetched data 202509160000 to 202509170000, size 35365\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509170000 to 202509180000\n",
            "Fetched data 202509170000 to 202509180000, size 35349\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509180000 to 202509190000\n",
            "Fetched data 202509180000 to 202509190000, size 35395\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509190000 to 202509200000\n",
            "Fetched data 202509190000 to 202509200000, size 35381\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509200000 to 202509210000\n",
            "Fetched data 202509200000 to 202509210000, size 35337\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509210000 to 202509220000\n",
            "Fetched data 202509210000 to 202509220000, size 35373\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509220000 to 202509230000\n",
            "Fetched data 202509220000 to 202509230000, size 35339\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509230000 to 202509240000\n",
            "Fetched data 202509230000 to 202509240000, size 35371\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509240000 to 202509250000\n",
            "Fetched data 202509240000 to 202509250000, size 35369\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509250000 to 202509260000\n",
            "Fetched data 202509250000 to 202509260000, size 35409\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509260000 to 202509270000\n",
            "Fetched data 202509260000 to 202509270000, size 35407\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509270000 to 202509280000\n",
            "Fetched data 202509270000 to 202509280000, size 35419\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509280000 to 202509290000\n",
            "Fetched data 202509280000 to 202509290000, size 35389\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509290000 to 202509300000\n",
            "Fetched data 202509290000 to 202509300000, size 35387\n",
            "Parsed records count: 192\n",
            "Attempt 1: fetching 202509300000 to 202510010000\n",
            "Fetched data 202509300000 to 202510010000, size 35387\n",
            "Parsed records count: 192\n",
            "Total rows in raw df: 3072\n",
            "Categories found in data: ['A04' 'A05']\n",
            "\n",
            "Final DataFrame preview:\n",
            "category            timestamp  imbalance_price  downward_price upward_price\n",
            "0         2025-09-15 00:00:00           124.46          124.46         None\n",
            "1         2025-09-15 00:15:00            69.22           69.22         None\n",
            "2         2025-09-15 00:30:00            68.99           68.99         None\n",
            "3         2025-09-15 00:45:00            52.71           52.71         None\n",
            "4         2025-09-15 01:00:00           -89.69          -89.69         None\n",
            "5         2025-09-15 01:15:00           -24.10          -24.10         None\n",
            "6         2025-09-15 01:30:00            58.07           58.07         None\n",
            "7         2025-09-15 01:45:00            26.43           26.43         None\n",
            "8         2025-09-15 02:00:00            47.10           47.10         None\n",
            "9         2025-09-15 02:15:00            38.59           38.59         None\n",
            "10        2025-09-15 02:30:00            51.95           51.95         None\n",
            "11        2025-09-15 02:45:00            93.25           93.25         None\n",
            "12        2025-09-15 03:00:00            27.59           27.59         None\n",
            "13        2025-09-15 03:15:00            42.37           42.37         None\n",
            "14        2025-09-15 03:30:00           106.86          106.86         None\n",
            "15        2025-09-15 03:45:00            68.95           68.95         None\n",
            "16        2025-09-15 04:00:00          -127.98         -127.98         None\n",
            "17        2025-09-15 04:15:00            56.98           56.98         None\n",
            "18        2025-09-15 04:30:00            60.25           60.25         None\n",
            "19        2025-09-15 04:45:00            53.18           53.18         None\n",
            "✅ Saved to entsoe_prices_combined.xlsx\n"
          ]
        }
      ]
    }
  ]
}